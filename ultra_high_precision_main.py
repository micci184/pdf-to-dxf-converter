#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
è¶…é«˜ç²¾åº¦æ‰‹æ›¸ãå›³é¢å°‚ç”¨ PDF to DXF ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼
æ‰‹æ›¸ãå›³é¢ã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸæœ€é«˜ç²¾åº¦å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import argparse
import cv2
import numpy as np
import pdf2image
from datetime import datetime
from sklearn.cluster import DBSCAN
from enhanced_dxf_writer import EnhancedDXFWriter

# EasyOCRã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False


class UltraHighPrecisionConverter:
    """è¶…é«˜ç²¾åº¦æ‰‹æ›¸ãå›³é¢å°‚ç”¨å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, pdf_path):
        """åˆæœŸåŒ–"""
        self.pdf_path = pdf_path
        self.images = []
        self.ocr_reader = None
        self.initialize_ocr()
        self.load_pdf()
    
    def initialize_ocr(self):
        """OCRåˆæœŸåŒ–"""
        if not EASYOCR_AVAILABLE:
            return
        
        try:
            print("ğŸ”¤ é«˜ç²¾åº¦OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
            self.ocr_reader = easyocr.Reader(['ja', 'en'], gpu=False)
            print("âœ… é«˜ç²¾åº¦OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ OCRåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.ocr_reader = None
    
    def load_pdf(self):
        """è¶…é«˜è§£åƒåº¦PDFãƒ­ãƒ¼ãƒ‰ï¼ˆæ‰‹æ›¸ãå›³é¢å°‚ç”¨ï¼‰"""
        try:
            print("ğŸ“– è¶…é«˜è§£åƒåº¦PDFèª­ã¿è¾¼ã¿ä¸­ï¼ˆæ‰‹æ›¸ãå›³é¢å°‚ç”¨ï¼‰...")
            # æ‰‹æ›¸ãå›³é¢ã«æœ€é©ãª600dpiè¨­å®š
            images = pdf2image.convert_from_path(self.pdf_path, dpi=600)
            
            for img in images:
                cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                self.images.append(cv_img)
            
            print(f"âœ… è¶…é«˜è§£åƒåº¦PDFèª­ã¿è¾¼ã¿å®Œäº†: {len(self.images)}ãƒšãƒ¼ã‚¸ (600dpi)")
        except Exception as e:
            raise Exception(f"PDFèª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")
    
    def advanced_preprocessing(self, image):
        """é«˜åº¦ãªæ‰‹æ›¸ãå›³é¢å°‚ç”¨å‰å‡¦ç†"""
        # ã‚«ãƒ©ãƒ¼æƒ…å ±ã‚’ä¿æŒ
        original = image.copy()
        
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. éå±€æ‰€å¹³å‡ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ï¼ˆæ‰‹æ›¸ããƒã‚¤ã‚ºå¯¾å¿œï¼‰
        denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
        
        # 2. ã‚¬ãƒ³ãƒè£œæ­£ï¼ˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ï¼‰
        gamma = 0.8  # æ‰‹æ›¸ãå›³é¢ã«æœ€é©
        look_up_table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        gamma_corrected = cv2.LUT(denoised, look_up_table)
        
        # 3. CLAHEï¼ˆå±€æ‰€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ï¼‰
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        clahe_image = clahe.apply(gamma_corrected)
        
        # 4. ã‚¨ãƒƒã‚¸ä¿æŒå¹³æ»‘åŒ–
        bilateral = cv2.bilateralFilter(clahe_image, 9, 75, 75)
        
        # 5. æ‰‹æ›¸ãå›³é¢å°‚ç”¨é©å¿œçš„äºŒå€¤åŒ–
        binary = cv2.adaptiveThreshold(
            bilateral, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 5, 3
        )
        
        # 6. è»½å¾®ãªãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†ï¼ˆæ‰‹æ›¸ãç·šã‚’ä¿è­·ï¼‰
        kernel = np.ones((1, 1), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        return original, gray, binary
    
    def comprehensive_color_detection(self, original_image):
        """åŒ…æ‹¬çš„è‰²ç·šæ¤œå‡ºï¼ˆæ‰‹æ›¸ãå›³é¢å°‚ç”¨ï¼‰"""
        # HSVã¨LABã®ä¸¡æ–¹ã‚’ä½¿ç”¨
        hsv = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)
        lab = cv2.cvtColor(original_image, cv2.COLOR_BGR2LAB)
        
        lines_by_color = {}
        
        # ğŸ”µ é’ã„ç·šã®åŒ…æ‹¬çš„æ¤œå‡º
        blue_masks = []
        
        # HSVã§ã®é’æ¤œå‡ºï¼ˆç¯„å›²æ‹¡å¤§ï¼‰
        blue_hsv_ranges = [
            ([90, 30, 30], [140, 255, 255]),    # æ¨™æº–é’
            ([80, 20, 20], [150, 255, 255]),    # ç¯„å›²æ‹¡å¤§é’
            ([95, 40, 40], [135, 200, 200]),    # æš—ã„é’
            ([100, 60, 60], [130, 255, 255])    # é®®ã‚„ã‹ãªé’
        ]
        
        for lower, upper in blue_hsv_ranges:
            blue_masks.append(cv2.inRange(hsv, np.array(lower), np.array(upper)))
        
        # BGRã§ã®é’æ¤œå‡ºï¼ˆç¯„å›²æ‹¡å¤§ï¼‰
        bgr_blue_ranges = [
            ([60, 0, 0], [255, 120, 120]),      # åŸºæœ¬é’
            ([40, 0, 0], [255, 100, 100]),      # è–„ã„é’
            ([80, 20, 20], [255, 150, 150]),    # æ¿ƒã„é’
            ([50, 10, 10], [255, 130, 130])     # ä¸­é–“é’
        ]
        
        for lower, upper in bgr_blue_ranges:
            blue_masks.append(cv2.inRange(original_image, np.array(lower), np.array(upper)))
        
        # LABã§ã®é’æ¤œå‡º
        lab_blue_lower = np.array([0, 120, 0])
        lab_blue_upper = np.array([255, 255, 120])
        blue_masks.append(cv2.inRange(lab, lab_blue_lower, lab_blue_upper))
        
        # å…¨ã¦ã®é’ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        blue_mask = blue_masks[0]
        for mask in blue_masks[1:]:
            blue_mask = cv2.bitwise_or(blue_mask, mask)
        
        # ãƒã‚¤ã‚ºé™¤å»ï¼ˆè»½å¾®ï¼‰
        kernel_light = np.ones((1, 1), np.uint8)
        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel_light)
        
        blue_lines = cv2.HoughLinesP(
            blue_mask, rho=1, theta=np.pi/180, threshold=15,
            minLineLength=10, maxLineGap=15
        )
        
        if blue_lines is not None:
            filtered_blue = self.smart_line_filtering(blue_lines)
            lines_by_color['blue'] = [(x1, y1, x2, y2, 'blue') for x1, y1, x2, y2 in filtered_blue]
        else:
            lines_by_color['blue'] = []
        
        # ğŸŸ¢ ç·‘ã®ç·šã®åŒ…æ‹¬çš„æ¤œå‡ºï¼ˆè›å…‰ç·‘é‡è¦–ï¼‰
        green_masks = []
        
        # HSVã§ã®ç·‘æ¤œå‡ºï¼ˆè›å…‰ç·‘å¯¾å¿œï¼‰
        green_hsv_ranges = [
            ([30, 40, 40], [90, 255, 255]),     # åŸºæœ¬ç·‘
            ([35, 60, 60], [85, 255, 255]),     # é®®ã‚„ã‹ãªç·‘
            ([40, 80, 80], [80, 255, 255]),     # è›å…‰ç·‘
            ([25, 30, 30], [95, 255, 255])      # ç¯„å›²æ‹¡å¤§ç·‘
        ]
        
        for lower, upper in green_hsv_ranges:
            green_masks.append(cv2.inRange(hsv, np.array(lower), np.array(upper)))
        
        # BGRã§ã®ç·‘æ¤œå‡º
        bgr_green_ranges = [
            ([0, 60, 0], [120, 255, 120]),      # åŸºæœ¬ç·‘
            ([0, 80, 0], [150, 255, 150]),      # é®®ã‚„ã‹ãªç·‘
            ([0, 40, 0], [100, 255, 100]),      # è–„ã„ç·‘
            ([0, 100, 0], [180, 255, 180])      # æ¿ƒã„ç·‘
        ]
        
        for lower, upper in bgr_green_ranges:
            green_masks.append(cv2.inRange(original_image, np.array(lower), np.array(upper)))
        
        # LABã§ã®ç·‘æ¤œå‡º
        lab_green_lower = np.array([0, 0, 130])
        lab_green_upper = np.array([255, 120, 255])
        green_masks.append(cv2.inRange(lab, lab_green_lower, lab_green_upper))
        
        # å…¨ã¦ã®ç·‘ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        green_mask = green_masks[0]
        for mask in green_masks[1:]:
            green_mask = cv2.bitwise_or(green_mask, mask)
        
        green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel_light)
        
        green_lines = cv2.HoughLinesP(
            green_mask, rho=1, theta=np.pi/180, threshold=15,
            minLineLength=10, maxLineGap=15
        )
        
        if green_lines is not None:
            filtered_green = self.smart_line_filtering(green_lines)
            lines_by_color['green'] = [(x1, y1, x2, y2, 'green') for x1, y1, x2, y2 in filtered_green]
        else:
            lines_by_color['green'] = []
        
        # ğŸ”´ èµ¤ã„ç·šã®åŒ…æ‹¬çš„æ¤œå‡ºï¼ˆæ‰‹æ›¸ãæ–‡å­—å¯¾å¿œï¼‰
        red_masks = []
        
        # HSVã§ã®èµ¤æ¤œå‡ºï¼ˆæ‰‹æ›¸ãå¯¾å¿œï¼‰
        red_hsv_ranges = [
            ([0, 40, 40], [15, 255, 255]),      # æ˜ã‚‹ã„èµ¤
            ([165, 40, 40], [180, 255, 255]),   # èµ¤ã®ä¸Šä½åŸŸ
            ([0, 30, 30], [20, 255, 255]),      # è–„ã„èµ¤
            ([160, 30, 30], [180, 255, 255])    # æš—ã„èµ¤
        ]
        
        for lower, upper in red_hsv_ranges:
            red_masks.append(cv2.inRange(hsv, np.array(lower), np.array(upper)))
        
        # BGRã§ã®èµ¤æ¤œå‡º
        bgr_red_ranges = [
            ([0, 0, 60], [120, 120, 255]),      # åŸºæœ¬èµ¤
            ([0, 0, 40], [100, 100, 255]),      # è–„ã„èµ¤
            ([0, 0, 80], [150, 150, 255]),      # æ¿ƒã„èµ¤
            ([0, 0, 50], [130, 130, 255])       # ä¸­é–“èµ¤
        ]
        
        for lower, upper in bgr_red_ranges:
            red_masks.append(cv2.inRange(original_image, np.array(lower), np.array(upper)))
        
        # LABã§ã®èµ¤æ¤œå‡º
        lab_red_lower = np.array([0, 130, 130])
        lab_red_upper = np.array([255, 255, 255])
        red_masks.append(cv2.inRange(lab, lab_red_lower, lab_red_upper))
        
        # å…¨ã¦ã®èµ¤ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        red_mask = red_masks[0]
        for mask in red_masks[1:]:
            red_mask = cv2.bitwise_or(red_mask, mask)
        
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel_light)
        
        red_lines = cv2.HoughLinesP(
            red_mask, rho=1, theta=np.pi/180, threshold=10,
            minLineLength=8, maxLineGap=20
        )
        
        if red_lines is not None:
            filtered_red = self.smart_line_filtering(red_lines)
            lines_by_color['red'] = [(x1, y1, x2, y2, 'red') for x1, y1, x2, y2 in filtered_red]
        else:
            lines_by_color['red'] = []
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒã‚¹ã‚¯ä¿å­˜
        cv2.imwrite('debug_ultra_blue_mask.png', blue_mask)
        cv2.imwrite('debug_ultra_green_mask.png', green_mask)
        cv2.imwrite('debug_ultra_red_mask.png', red_mask)
        
        print(f"ğŸ” åŒ…æ‹¬çš„è‰²ç·šæ¤œå‡º: é’={len(lines_by_color['blue'])}æœ¬, "
              f"ç·‘={len(lines_by_color['green'])}æœ¬, èµ¤={len(lines_by_color['red'])}æœ¬")
        
        return lines_by_color
    
    def smart_line_filtering(self, lines):
        """è³¢ã„ç·šåˆ†ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ‰‹æ›¸ãå›³é¢å°‚ç”¨ï¼‰"""
        if lines is None or len(lines) == 0:
            return []
        
        lines_reshaped = lines.reshape(-1, 4)
        filtered_lines = []
        
        for line in lines_reshaped:
            x1, y1, x2, y2 = line
            
            # ç·šã®é•·ã•ã¨è§’åº¦ã‚’è¨ˆç®—
            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            
            # æ‰‹æ›¸ãå›³é¢ã«é©ã—ãŸç·©ã„æ¡ä»¶
            if length >= 5:  # 5ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šã®ç·šåˆ†ã‚’æ¡ç”¨
                # æ°´å¹³ãƒ»å‚ç›´ãƒ»æ–œã‚ç·šã‚’å¹…åºƒãå—ã‘å…¥ã‚Œ
                if (abs(angle) < 15 or abs(angle - 90) < 15 or 
                    abs(angle - 180) < 15 or abs(angle + 90) < 15 or
                    abs(angle - 45) < 20 or abs(angle + 45) < 20 or
                    length > 25):  # é•·ã„ç·šã¯è§’åº¦ã«é–¢ä¿‚ãªãæ¡ç”¨
                    filtered_lines.append(line)
        
        return filtered_lines
    
    def extract_structure_lines(self, binary):
        """æ§‹é€ ç·šæŠ½å‡ºï¼ˆæ‰‹æ›¸ãå›³é¢æœ€é©åŒ–ï¼‰"""
        # è¤‡æ•°ã®é–¾å€¤ã§ç·šåˆ†æ¤œå‡ºã‚’å®Ÿè¡Œ
        all_lines = []
        
        # å³æ ¼ãªæ¤œå‡º
        lines_strict = cv2.HoughLinesP(
            binary, rho=1, theta=np.pi/180, threshold=50,
            minLineLength=30, maxLineGap=10
        )
        if lines_strict is not None:
            all_lines.extend(lines_strict.reshape(-1, 4))
        
        # ä¸­ç¨‹åº¦ã®æ¤œå‡º
        lines_moderate = cv2.HoughLinesP(
            binary, rho=1, theta=np.pi/180, threshold=30,
            minLineLength=20, maxLineGap=15
        )
        if lines_moderate is not None:
            all_lines.extend(lines_moderate.reshape(-1, 4))
        
        # ç·©ã„æ¤œå‡ºï¼ˆç´°ã‹ã„ç·šå¯¾å¿œï¼‰
        lines_loose = cv2.HoughLinesP(
            binary, rho=1, theta=np.pi/180, threshold=15,
            minLineLength=10, maxLineGap=20
        )
        if lines_loose is not None:
            all_lines.extend(lines_loose.reshape(-1, 4))
        
        if not all_lines:
            return []
        
        # é‡è¤‡é™¤å»ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        unique_lines = self.remove_duplicate_lines(all_lines)
        
        return unique_lines
    
    def remove_duplicate_lines(self, lines):
        """é‡è¤‡ç·šåˆ†ã®é™¤å»ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        if len(lines) == 0:
            return []
        
        # ç·šåˆ†ã®ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆä¸­ç‚¹ã€è§’åº¦ã€é•·ã•ï¼‰
        features = []
        for x1, y1, x2, y2 in lines:
            mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2
            angle = np.arctan2(y2 - y1, x2 - x1)
            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            features.append([mid_x, mid_y, angle * 100, length])  # è§’åº¦ã«é‡ã¿ã‚’ä»˜åŠ 
        
        features = np.array(features)
        
        # DBSCANã§é¡ä¼¼ç·šåˆ†ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        if len(features) > 1:
            clustering = DBSCAN(eps=25, min_samples=1).fit(features)
            labels = clustering.labels_
            
            # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‹ã‚‰æœ€é©ãªç·šåˆ†ã‚’é¸æŠ
            unique_lines = []
            unique_labels = set(labels)
            
            for label in unique_labels:
                cluster_indices = np.where(labels == label)[0]
                cluster_lines = [lines[i] for i in cluster_indices]
                
                if len(cluster_lines) == 1:
                    unique_lines.extend(cluster_lines)
                else:
                    # æœ€é•·ã®ç·šåˆ†ã‚’é¸æŠ
                    best_line = max(cluster_lines, 
                                  key=lambda l: np.sqrt((l[2]-l[0])**2 + (l[3]-l[1])**2))
                    unique_lines.append(best_line)
            
            return unique_lines
        else:
            return lines
    
    def enhanced_text_recognition(self, image):
        """å¼·åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ï¼ˆæ‰‹æ›¸ãç‰¹åŒ–ï¼‰"""
        if not self.ocr_reader:
            return []
        
        try:
            print("ğŸ”¤ æ‰‹æ›¸ãç‰¹åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å‡¦ç†ä¸­...")
            
            # è¤‡æ•°ã®å‰å‡¦ç†ã§OCRå®Ÿè¡Œ
            text_regions = []
            seen_texts = set()
            
            # 1. ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã§OCR
            results_original = self.ocr_reader.readtext(image)
            
            # 2. ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ç”»åƒã§OCR
            enhanced = cv2.convertScaleAbs(image, alpha=1.5, beta=20)
            results_enhanced = self.ocr_reader.readtext(enhanced)
            
            # 3. ã‚¬ãƒ³ãƒè£œæ­£ç”»åƒã§OCR
            gamma = 0.7
            look_up_table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
            gamma_corrected = cv2.LUT(image, look_up_table)
            results_gamma = self.ocr_reader.readtext(gamma_corrected)
            
            # å…¨ã¦ã®çµæœã‚’çµ±åˆ
            all_results = results_original + results_enhanced + results_gamma
            
            # è‰²åˆ¥ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # èµ¤ã„ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹åˆ¥å‡¦ç†
            red_lower1 = np.array([0, 30, 30])
            red_upper1 = np.array([15, 255, 255])
            red_mask1 = cv2.inRange(hsv, red_lower1, red_upper1)
            
            red_lower2 = np.array([165, 30, 30])
            red_upper2 = np.array([180, 255, 255])
            red_mask2 = cv2.inRange(hsv, red_lower2, red_upper2)
            
            red_mask = cv2.bitwise_or(red_mask1, red_mask2)
            
            for (bbox, text, confidence) in all_results:
                if confidence > 0.3:  # æ‰‹æ›¸ããªã®ã§ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹
                    cleaned_text = text.strip()
                    if (len(cleaned_text) > 0 and not cleaned_text.isspace() 
                        and cleaned_text not in seen_texts):
                        seen_texts.add(cleaned_text)
                        
                        x_coords = [point[0] for point in bbox]
                        y_coords = [point[1] for point in bbox]
                        x1, y1 = int(min(x_coords)), int(min(y_coords))
                        x2, y2 = int(max(x_coords)), int(max(y_coords))
                        
                        # è‰²åˆ¤å®š
                        text_center_x = (x1 + x2) // 2
                        text_center_y = (y1 + y2) // 2
                        is_red_text = False
                        
                        if (0 <= text_center_y < red_mask.shape[0] and 
                            0 <= text_center_x < red_mask.shape[1]):
                            is_red_text = red_mask[text_center_y, text_center_x] > 0
                        
                        text_regions.append({
                            'bbox': (x1, y1, x2, y2),
                            'text': cleaned_text,
                            'confidence': confidence,
                            'color': 'red' if is_red_text else 'black'
                        })
            
            red_text_count = sum(1 for t in text_regions if t.get('color') == 'red')
            print(f"âœ… æ‰‹æ›¸ãç‰¹åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å®Œäº†: {len(text_regions)}å€‹ (èµ¤æ–‡å­—: {red_text_count}å€‹)")
            return text_regions
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def process_pdf_ultra_precision(self):
        """è¶…é«˜ç²¾åº¦PDFãƒ—ãƒ­ã‚»ã‚·ãƒ³ã‚°"""
        try:
            print("ğŸš€ è¶…é«˜ç²¾åº¦æ‰‹æ›¸ãå›³é¢å‡¦ç†é–‹å§‹")
            
            all_elements = {
                'blue_lines': [],
                'green_lines': [],
                'red_lines': [],
                'main_lines': [],
                'text_regions': []
            }
            
            for i, image in enumerate(self.images):
                print(f"ğŸ” ãƒšãƒ¼ã‚¸ {i+1} ã‚’è¶…é«˜ç²¾åº¦å‡¦ç†ä¸­...")
                
                # 1. é«˜åº¦ãªå‰å‡¦ç†
                original, gray, binary = self.advanced_preprocessing(image)
                
                # 2. åŒ…æ‹¬çš„è‰²ç·šæ¤œå‡º
                color_lines = self.comprehensive_color_detection(original)
                all_elements['blue_lines'].extend(color_lines.get('blue', []))
                all_elements['green_lines'].extend(color_lines.get('green', []))
                all_elements['red_lines'].extend(color_lines.get('red', []))
                
                # 3. æ§‹é€ ç·šæŠ½å‡º
                main_lines = self.extract_structure_lines(binary)
                all_elements['main_lines'].extend(main_lines)
                
                # 4. å¼·åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜
                text_regions = self.enhanced_text_recognition(original)
                all_elements['text_regions'].extend(text_regions)
                
                print(f"âœ… ãƒšãƒ¼ã‚¸ {i+1} è¶…é«˜ç²¾åº¦å‡¦ç†å®Œäº†:")
                print(f"   ğŸ”µ é’ç·š: {len(color_lines.get('blue', []))}æœ¬")
                print(f"   ğŸŸ¢ ç·‘ç·š: {len(color_lines.get('green', []))}æœ¬")
                print(f"   ğŸ”´ èµ¤ç·š: {len(color_lines.get('red', []))}æœ¬")
                print(f"   ğŸ“ ä¸»è¦ç·š: {len(main_lines)}æœ¬")
                print(f"   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {len(text_regions)}å€‹")
            
            return all_elements
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def create_visualization(self, elements, output_path):
        """å¯è¦–åŒ–ç”»åƒä½œæˆ"""
        try:
            if not self.images:
                return
            
            # æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’ãƒ™ãƒ¼ã‚¹ã«å¯è¦–åŒ–
            base_image = self.images[0].copy()
            height, width = base_image.shape[:2]
            
            # ç™½ã„èƒŒæ™¯ã‚’ä½œæˆ
            vis_image = np.ones((height, width, 3), dtype=np.uint8) * 255
            
            # å…ƒã®ç”»åƒã‚’è–„ãé‡ã­ã‚‹
            alpha = 0.3
            vis_image = cv2.addWeighted(vis_image, 1-alpha, base_image, alpha, 0)
            
            # ç·šåˆ†ã‚’æç”»
            # é»’ã„ç·šï¼ˆä¸»è¦æ§‹é€ ç·šï¼‰
            for line in elements['main_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 0), 2)
            
            # é’ã„ç·š
            for line in elements['blue_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
            
            # ç·‘ã®ç·š
            for line in elements['green_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            
            # èµ¤ã„ç·š
            for line in elements['red_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
            
            # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æç”»
            for text_region in elements['text_regions']:
                x1, y1, x2, y2 = text_region['bbox']
                color = (0, 0, 255) if text_region.get('color') == 'red' else (255, 0, 255)
                cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 1)
                
                # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
                cv2.putText(vis_image, text_region['text'], (x1, y1-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            
            # å¯è¦–åŒ–ç”»åƒã‚’ä¿å­˜
            cv2.imwrite(output_path, vis_image)
            print(f"ğŸ“¸ å¯è¦–åŒ–ç”»åƒã‚’ä¿å­˜: {output_path}")
            
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def convert_pdf_ultra_precision(input_path, output_path, scale=100, visualization=True):
    """è¶…é«˜ç²¾åº¦PDFå¤‰æ›"""
    try:
        print("=" * 70)
        print("ğŸš€ è¶…é«˜ç²¾åº¦æ‰‹æ›¸ãå›³é¢å°‚ç”¨ PDF to DXF å¤‰æ›ãƒ„ãƒ¼ãƒ« ğŸš€")
        print("=" * 70)
        
        # 1. å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        converter = UltraHighPrecisionConverter(input_path)
        
        # 2. è¶…é«˜ç²¾åº¦å‡¦ç†
        elements = converter.process_pdf_ultra_precision()
        
        if elements is None:
            return False
        
        # 3. DXFç”Ÿæˆ
        print("ğŸ“ è¶…é«˜ç²¾åº¦DXFç”Ÿæˆä¸­...")
        dxf_writer = EnhancedDXFWriter()
        
        if scale != 1:
            dxf_writer.set_scale(1.0 / scale)
        
        # è¶…é«˜ç²¾åº¦è¦ç´ ã‚’DXFã«è¿½åŠ 
        dxf_elements = {
            'lines': elements['main_lines'],
            'blue_lines': elements['blue_lines'],
            'green_lines': elements['green_lines'],
            'red_lines': elements['red_lines'],
            'text_regions': elements['text_regions']
        }
        
        dxf_writer.add_elements(dxf_elements)
        dxf_writer.save(output_path)
        
        # 4. å¯è¦–åŒ–ç”»åƒç”Ÿæˆ
        if visualization:
            vis_path = output_path.replace('.dxf', '_ultra_precision_vis.png')
            converter.create_visualization(elements, vis_path)
        
        # 5. çµæœè¡¨ç¤º
        total_lines = (len(elements['main_lines']) + len(elements['blue_lines']) + 
                      len(elements['green_lines']) + len(elements['red_lines']))
        
        print("=" * 70)
        print("ğŸ‰ è¶…é«˜ç²¾åº¦å¤‰æ›å®Œäº† ğŸ‰")
        print("=" * 70)
        print(f"ğŸ“ å…¥åŠ›: {input_path}")
        print(f"ğŸ“ å‡ºåŠ›: {output_path}")
        print(f"ğŸ“Š è¶…é«˜ç²¾åº¦æ¤œå‡ºçµæœ:")
        print(f"   ğŸ”µ é’ç·š: {len(elements['blue_lines'])}æœ¬")
        print(f"   ğŸŸ¢ ç·‘ç·š: {len(elements['green_lines'])}æœ¬")
        print(f"   ğŸ”´ èµ¤ç·š: {len(elements['red_lines'])}æœ¬")
        print(f"   ğŸ“ ä¸»è¦ç·š: {len(elements['main_lines'])}æœ¬")
        print(f"   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {len(elements['text_regions'])}å€‹")
        print(f"   ğŸ¯ ç·ç·šåˆ†æ•°: {total_lines}æœ¬")
        print("ğŸš€ æ‰‹æ›¸ãå›³é¢ã«ç‰¹åŒ–ã—ãŸè¶…é«˜ç²¾åº¦å¤‰æ›å®Œäº†ï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ğŸš€ è¶…é«˜ç²¾åº¦æ‰‹æ›¸ãå›³é¢å°‚ç”¨ PDFå¤‰æ›ãƒ„ãƒ¼ãƒ« ğŸš€')
    parser.add_argument('--input', '-i', required=True, help='å…¥åŠ›PDFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›DXFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--scale', '-s', type=int, default=100, help='ã‚¹ã‚±ãƒ¼ãƒ«')
    parser.add_argument('--visualization', '-v', action='store_true', help='å¯è¦–åŒ–ç”»åƒã‚’ç”Ÿæˆ')
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
    if args.output:
        output_path = f"output/{args.output}"
    else:
        base_name = os.path.splitext(os.path.basename(args.input))[0]
        now = datetime.now()
        timestamp = now.strftime("%Y%m%d_%H%M")
        output_path = f"output/{timestamp}_{base_name}_ultra_precision.dxf"
    
    # å¤‰æ›å®Ÿè¡Œ
    success = convert_pdf_ultra_precision(
        args.input,
        output_path,
        args.scale,
        args.visualization
    )
    
    if success:
        print("âœ… è¶…é«˜ç²¾åº¦å¤‰æ›ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        sys.exit(0)
    else:
        print("âŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
