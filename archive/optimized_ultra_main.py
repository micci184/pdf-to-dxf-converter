#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æœ€é©åŒ–è¶…é«˜ç²¾åº¦ PDF to DXF ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼
è¶…é«˜ç²¾åº¦æ¤œå‡º + é‡è¤‡é™¤å»æœ€é©åŒ– + å®Ÿç”¨æ€§é‡è¦–
"""

import os
import sys
import argparse
import cv2
import numpy as np
import pdf2image
from datetime import datetime
from sklearn.cluster import DBSCAN
from enhanced_dxf_writer import EnhancedDXFWriter

# EasyOCRã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False


class OptimizedUltraConverter:
    """æœ€é©åŒ–è¶…é«˜ç²¾åº¦å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, pdf_path):
        """åˆæœŸåŒ–"""
        self.pdf_path = pdf_path
        self.images = []
        self.ocr_reader = None
        self.initialize_ocr()
        self.load_pdf()
    
    def initialize_ocr(self):
        """OCRåˆæœŸåŒ–"""
        if not EASYOCR_AVAILABLE:
            return
        
        try:
            print("ğŸ”¤ æœ€é©åŒ–OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
            self.ocr_reader = easyocr.Reader(['ja', 'en'], gpu=False)
            print("âœ… æœ€é©åŒ–OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ OCRåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.ocr_reader = None
    
    def load_pdf(self):
        """æœ€é©åŒ–é«˜è§£åƒåº¦PDFãƒ­ãƒ¼ãƒ‰"""
        try:
            print("ğŸ“– æœ€é©åŒ–é«˜è§£åƒåº¦PDFèª­ã¿è¾¼ã¿ä¸­...")
            # 500dpiã§å“è³ªã¨å‡¦ç†é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ã‚’é‡è¦–
            images = pdf2image.convert_from_path(self.pdf_path, dpi=500)
            
            for img in images:
                cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                self.images.append(cv_img)
            
            print(f"âœ… æœ€é©åŒ–é«˜è§£åƒåº¦PDFèª­ã¿è¾¼ã¿å®Œäº†: {len(self.images)}ãƒšãƒ¼ã‚¸ (500dpi)")
        except Exception as e:
            raise Exception(f"PDFèª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")
    
    def optimized_preprocessing(self, image):
        """æœ€é©åŒ–å‰å‡¦ç†"""
        original = image.copy()
        
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. éå±€æ‰€å¹³å‡ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°
        denoised = cv2.fastNlMeansDenoising(gray, None, 8, 7, 21)
        
        # 2. ã‚¬ãƒ³ãƒè£œæ­£
        gamma = 0.85
        look_up_table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        gamma_corrected = cv2.LUT(denoised, look_up_table)
        
        # 3. CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))
        clahe_image = clahe.apply(gamma_corrected)
        
        # 4. é©å¿œçš„äºŒå€¤åŒ–
        binary = cv2.adaptiveThreshold(
            clahe_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 5, 2
        )
        
        return original, gray, binary
    
    def optimized_color_detection(self, original_image):
        """æœ€é©åŒ–è‰²ç·šæ¤œå‡º"""
        hsv = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)
        lines_by_color = {'blue': [], 'green': [], 'red': []}
        
        # é’ç·šæ¤œå‡ºï¼ˆæœ€é©åŒ–ï¼‰
        blue_masks = []
        blue_hsv_ranges = [
            ([90, 30, 30], [140, 255, 255]),
            ([80, 20, 20], [150, 255, 255]),
            ([95, 40, 40], [135, 200, 200])
        ]
        
        for lower, upper in blue_hsv_ranges:
            blue_masks.append(cv2.inRange(hsv, np.array(lower), np.array(upper)))
        
        bgr_blue_ranges = [
            ([60, 0, 0], [255, 120, 120]),
            ([40, 0, 0], [255, 100, 100])
        ]
        
        for lower, upper in bgr_blue_ranges:
            blue_masks.append(cv2.inRange(original_image, np.array(lower), np.array(upper)))
        
        blue_mask = blue_masks[0]
        for mask in blue_masks[1:]:
            blue_mask = cv2.bitwise_or(blue_mask, mask)
        
        blue_lines = cv2.HoughLinesP(
            blue_mask, rho=1, theta=np.pi/180, threshold=20,
            minLineLength=12, maxLineGap=18
        )
        
        if blue_lines is not None:
            filtered_blue = self.optimized_line_filtering(blue_lines)
            lines_by_color['blue'] = [(x1, y1, x2, y2, 'blue') for x1, y1, x2, y2 in filtered_blue]
        
        # ç·‘ç·šæ¤œå‡ºï¼ˆæœ€é©åŒ–ï¼‰
        green_masks = []
        green_hsv_ranges = [
            ([30, 40, 40], [90, 255, 255]),
            ([35, 60, 60], [85, 255, 255]),
            ([40, 80, 80], [80, 255, 255])
        ]
        
        for lower, upper in green_hsv_ranges:
            green_masks.append(cv2.inRange(hsv, np.array(lower), np.array(upper)))
        
        bgr_green_ranges = [
            ([0, 60, 0], [120, 255, 120]),
            ([0, 80, 0], [150, 255, 150])
        ]
        
        for lower, upper in bgr_green_ranges:
            green_masks.append(cv2.inRange(original_image, np.array(lower), np.array(upper)))
        
        green_mask = green_masks[0]
        for mask in green_masks[1:]:
            green_mask = cv2.bitwise_or(green_mask, mask)
        
        green_lines = cv2.HoughLinesP(
            green_mask, rho=1, theta=np.pi/180, threshold=20,
            minLineLength=12, maxLineGap=18
        )
        
        if green_lines is not None:
            filtered_green = self.optimized_line_filtering(green_lines)
            lines_by_color['green'] = [(x1, y1, x2, y2, 'green') for x1, y1, x2, y2 in filtered_green]
        
        # èµ¤ç·šæ¤œå‡ºï¼ˆæœ€é©åŒ–ï¼‰
        red_masks = []
        red_hsv_ranges = [
            ([0, 40, 40], [15, 255, 255]),
            ([165, 40, 40], [180, 255, 255])
        ]
        
        for lower, upper in red_hsv_ranges:
            red_masks.append(cv2.inRange(hsv, np.array(lower), np.array(upper)))
        
        bgr_red_ranges = [
            ([0, 0, 60], [120, 120, 255]),
            ([0, 0, 40], [100, 100, 255])
        ]
        
        for lower, upper in bgr_red_ranges:
            red_masks.append(cv2.inRange(original_image, np.array(lower), np.array(upper)))
        
        red_mask = red_masks[0]
        for mask in red_masks[1:]:
            red_mask = cv2.bitwise_or(red_mask, mask)
        
        red_lines = cv2.HoughLinesP(
            red_mask, rho=1, theta=np.pi/180, threshold=15,
            minLineLength=10, maxLineGap=25
        )
        
        if red_lines is not None:
            filtered_red = self.optimized_line_filtering(red_lines)
            lines_by_color['red'] = [(x1, y1, x2, y2, 'red') for x1, y1, x2, y2 in filtered_red]
        
        print(f"ğŸ” æœ€é©åŒ–è‰²ç·šæ¤œå‡º: é’={len(lines_by_color['blue'])}æœ¬, "
              f"ç·‘={len(lines_by_color['green'])}æœ¬, èµ¤={len(lines_by_color['red'])}æœ¬")
        
        return lines_by_color
    
    def optimized_line_filtering(self, lines):
        """æœ€é©åŒ–ç·šåˆ†ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        if lines is None or len(lines) == 0:
            return []
        
        lines_reshaped = lines.reshape(-1, 4)
        filtered_lines = []
        
        for line in lines_reshaped:
            x1, y1, x2, y2 = line
            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            
            # é•·ã•ã«ã‚ˆã‚‹åŸºæœ¬ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if length >= 8:  # 8ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Š
                angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                
                # è§’åº¦ã«ã‚ˆã‚‹åˆ¤å®šï¼ˆç·©ã„æ¡ä»¶ï¼‰
                if (abs(angle) < 12 or abs(angle - 90) < 12 or 
                    abs(angle - 180) < 12 or abs(angle + 90) < 12 or
                    abs(angle - 45) < 18 or abs(angle + 45) < 18 or
                    length > 25):
                    filtered_lines.append(line)
        
        return filtered_lines
    
    def extract_optimized_structure_lines(self, binary):
        """æœ€é©åŒ–æ§‹é€ ç·šæŠ½å‡º"""
        all_lines = []
        
        # è¤‡æ•°ã®é–¾å€¤ã§æ¤œå‡º
        thresholds = [60, 40, 25]
        min_lengths = [35, 25, 15]
        max_gaps = [8, 15, 25]
        
        for threshold, min_length, max_gap in zip(thresholds, min_lengths, max_gaps):
            lines = cv2.HoughLinesP(
                binary, rho=1, theta=np.pi/180, threshold=threshold,
                minLineLength=min_length, maxLineGap=max_gap
            )
            if lines is not None:
                all_lines.extend(lines.reshape(-1, 4))
        
        if not all_lines:
            return []
        
        # é‡è¤‡é™¤å»ã¨æœ€é©åŒ–
        optimized_lines = self.advanced_duplicate_removal(all_lines)
        
        return optimized_lines
    
    def advanced_duplicate_removal(self, lines):
        """é«˜åº¦ãªé‡è¤‡é™¤å»ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        if len(lines) == 0:
            return []
        
        # åŸºæœ¬çš„ãªé‡è¤‡é™¤å»
        unique_lines = []
        tolerance = 20  # ãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã®è¨±å®¹ç¯„å›²
        
        for current_line in lines:
            x1, y1, x2, y2 = current_line
            is_duplicate = False
            
            for existing_line in unique_lines[:]:  # ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦å®‰å…¨ã«å‰Šé™¤
                ex1, ey1, ex2, ey2 = existing_line
                
                # ç«¯ç‚¹é–“ã®è·é›¢ã‚’è¨ˆç®—
                dist1 = ((x1-ex1)**2 + (y1-ey1)**2)**0.5
                dist2 = ((x2-ex2)**2 + (y2-ey2)**2)**0.5
                dist3 = ((x1-ex2)**2 + (y1-ey2)**2)**0.5
                dist4 = ((x2-ex1)**2 + (y2-ey1)**2)**0.5
                
                # é †æ–¹å‘ã¾ãŸã¯é€†æ–¹å‘ã§é¡ä¼¼ã—ã¦ã„ã‚Œã°é‡è¤‡ã¨ã¿ãªã™
                if (dist1 < tolerance and dist2 < tolerance) or (dist3 < tolerance and dist4 < tolerance):
                    is_duplicate = True
                    # ã‚ˆã‚Šé•·ã„ç·šåˆ†ã‚’é¸æŠ
                    current_length = ((x2-x1)**2 + (y2-y1)**2)**0.5
                    existing_length = ((ex2-ex1)**2 + (ey2-ey1)**2)**0.5
                    if current_length > existing_length:
                        # æ—¢å­˜ã®ç·šåˆ†ã‚’ç½®ãæ›ãˆ
                        try:
                            unique_lines.remove(existing_line)
                            unique_lines.append(current_line.tolist() if hasattr(current_line, 'tolist') else current_line)
                        except ValueError:
                            pass
                    break
            
            if not is_duplicate:
                unique_lines.append(current_line.tolist() if hasattr(current_line, 'tolist') else current_line)
        
        # é•·ã•ã«ã‚ˆã‚‹æœ€çµ‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        final_lines = []
        for line in unique_lines:
            x1, y1, x2, y2 = line
            length = ((x2-x1)**2 + (y2-y1)**2)**0.5
            if length >= 8:  # 8ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šã®ç·šåˆ†ã®ã¿
                final_lines.append(line)
        
        return final_lines
    
    def optimized_text_recognition(self, image):
        """æœ€é©åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜"""
        if not self.ocr_reader:
            return []
        
        try:
            print("ğŸ”¤ æœ€é©åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å‡¦ç†ä¸­...")
            
            # è¤‡æ•°ã®å‰å‡¦ç†ã§OCRå®Ÿè¡Œ
            text_regions = []
            seen_texts = set()
            
            # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã§OCR
            results = self.ocr_reader.readtext(image)
            
            # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ç”»åƒã§OCR
            enhanced = cv2.convertScaleAbs(image, alpha=1.3, beta=15)
            results_enhanced = self.ocr_reader.readtext(enhanced)
            
            all_results = results + results_enhanced
            
            for (bbox, text, confidence) in all_results:
                if confidence > 0.4:
                    cleaned_text = text.strip()
                    if (len(cleaned_text) > 0 and not cleaned_text.isspace() 
                        and cleaned_text not in seen_texts):
                        seen_texts.add(cleaned_text)
                        
                        x_coords = [point[0] for point in bbox]
                        y_coords = [point[1] for point in bbox]
                        x1, y1 = int(min(x_coords)), int(min(y_coords))
                        x2, y2 = int(max(x_coords)), int(max(y_coords))
                        
                        text_regions.append({
                            'bbox': (x1, y1, x2, y2),
                            'text': cleaned_text,
                            'confidence': confidence,
                            'color': 'black'
                        })
            
            print(f"âœ… æœ€é©åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å®Œäº†: {len(text_regions)}å€‹")
            return text_regions
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def process_pdf_optimized_ultra(self):
        """æœ€é©åŒ–è¶…é«˜ç²¾åº¦PDFãƒ—ãƒ­ã‚»ã‚·ãƒ³ã‚°"""
        try:
            print("âš¡ æœ€é©åŒ–è¶…é«˜ç²¾åº¦å‡¦ç†é–‹å§‹")
            
            all_elements = {
                'blue_lines': [],
                'green_lines': [],
                'red_lines': [],
                'main_lines': [],
                'text_regions': []
            }
            
            for i, image in enumerate(self.images):
                print(f"ğŸ” ãƒšãƒ¼ã‚¸ {i+1} ã‚’æœ€é©åŒ–è¶…é«˜ç²¾åº¦å‡¦ç†ä¸­...")
                
                # 1. æœ€é©åŒ–å‰å‡¦ç†
                original, gray, binary = self.optimized_preprocessing(image)
                
                # 2. æœ€é©åŒ–è‰²ç·šæ¤œå‡º
                color_lines = self.optimized_color_detection(original)
                all_elements['blue_lines'].extend(color_lines.get('blue', []))
                all_elements['green_lines'].extend(color_lines.get('green', []))
                all_elements['red_lines'].extend(color_lines.get('red', []))
                
                # 3. æœ€é©åŒ–æ§‹é€ ç·šæŠ½å‡º
                main_lines = self.extract_optimized_structure_lines(binary)
                all_elements['main_lines'].extend(main_lines)
                
                # 4. æœ€é©åŒ–ãƒ†ã‚­ã‚¹ãƒˆèªè­˜
                text_regions = self.optimized_text_recognition(original)
                all_elements['text_regions'].extend(text_regions)
                
                print(f"âœ… ãƒšãƒ¼ã‚¸ {i+1} æœ€é©åŒ–è¶…é«˜ç²¾åº¦å‡¦ç†å®Œäº†:")
                print(f"   ğŸ”µ é’ç·š: {len(color_lines.get('blue', []))}æœ¬")
                print(f"   ğŸŸ¢ ç·‘ç·š: {len(color_lines.get('green', []))}æœ¬")
                print(f"   ğŸ”´ èµ¤ç·š: {len(color_lines.get('red', []))}æœ¬")
                print(f"   ğŸ“ ä¸»è¦ç·š: {len(main_lines)}æœ¬")
                print(f"   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {len(text_regions)}å€‹")
            
            return all_elements
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def create_visualization(self, elements, output_path):
        """å¯è¦–åŒ–ç”»åƒä½œæˆ"""
        try:
            if not self.images:
                return
            
            base_image = self.images[0].copy()
            height, width = base_image.shape[:2]
            
            vis_image = np.ones((height, width, 3), dtype=np.uint8) * 255
            alpha = 0.3
            vis_image = cv2.addWeighted(vis_image, 1-alpha, base_image, alpha, 0)
            
            # ç·šåˆ†ã‚’æç”»
            for line in elements['main_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 0), 2)
            
            for line in elements['blue_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
            
            for line in elements['green_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            
            for line in elements['red_lines']:
                x1, y1, x2, y2 = line[:4]
                cv2.line(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
            
            # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æç”»
            for text_region in elements['text_regions']:
                x1, y1, x2, y2 = text_region['bbox']
                cv2.rectangle(vis_image, (x1, y1), (x2, y2), (255, 0, 255), 1)
                cv2.putText(vis_image, text_region['text'], (x1, y1-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)
            
            cv2.imwrite(output_path, vis_image)
            print(f"ğŸ“¸ å¯è¦–åŒ–ç”»åƒã‚’ä¿å­˜: {output_path}")
            
        except Exception as e:
            print(f"âš ï¸ å¯è¦–åŒ–ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")


def convert_pdf_optimized_ultra(input_path, output_path, scale=100, visualization=True):
    """æœ€é©åŒ–è¶…é«˜ç²¾åº¦PDFå¤‰æ›"""
    try:
        print("=" * 70)
        print("âš¡ æœ€é©åŒ–è¶…é«˜ç²¾åº¦ PDF to DXF å¤‰æ›ãƒ„ãƒ¼ãƒ« âš¡")
        print("=" * 70)
        
        # 1. å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        converter = OptimizedUltraConverter(input_path)
        
        # 2. æœ€é©åŒ–è¶…é«˜ç²¾åº¦å‡¦ç†
        elements = converter.process_pdf_optimized_ultra()
        
        if elements is None:
            return False
        
        # 3. DXFç”Ÿæˆ
        print("ğŸ“ æœ€é©åŒ–è¶…é«˜ç²¾åº¦DXFç”Ÿæˆä¸­...")
        dxf_writer = EnhancedDXFWriter()
        
        if scale != 1:
            dxf_writer.set_scale(1.0 / scale)
        
        dxf_elements = {
            'lines': elements['main_lines'],
            'blue_lines': elements['blue_lines'],
            'green_lines': elements['green_lines'],
            'red_lines': elements['red_lines'],
            'text_regions': elements['text_regions']
        }
        
        dxf_writer.add_elements(dxf_elements)
        dxf_writer.save(output_path)
        
        # 4. å¯è¦–åŒ–ç”»åƒç”Ÿæˆ
        if visualization:
            vis_path = output_path.replace('.dxf', '_optimized_ultra_vis.png')
            converter.create_visualization(elements, vis_path)
        
        # 5. çµæœè¡¨ç¤º
        total_lines = (len(elements['main_lines']) + len(elements['blue_lines']) + 
                      len(elements['green_lines']) + len(elements['red_lines']))
        
        print("=" * 70)
        print("ğŸ‰ æœ€é©åŒ–è¶…é«˜ç²¾åº¦å¤‰æ›å®Œäº† ğŸ‰")
        print("=" * 70)
        print(f"ğŸ“ å…¥åŠ›: {input_path}")
        print(f"ğŸ“ å‡ºåŠ›: {output_path}")
        print(f"ğŸ“Š æœ€é©åŒ–è¶…é«˜ç²¾åº¦æ¤œå‡ºçµæœ:")
        print(f"   ğŸ”µ é’ç·š: {len(elements['blue_lines'])}æœ¬")
        print(f"   ğŸŸ¢ ç·‘ç·š: {len(elements['green_lines'])}æœ¬")
        print(f"   ğŸ”´ èµ¤ç·š: {len(elements['red_lines'])}æœ¬")
        print(f"   ğŸ“ ä¸»è¦ç·š: {len(elements['main_lines'])}æœ¬")
        print(f"   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {len(elements['text_regions'])}å€‹")
        print(f"   ğŸ¯ ç·ç·šåˆ†æ•°: {total_lines}æœ¬ï¼ˆé‡è¤‡é™¤å»æœ€é©åŒ–æ¸ˆã¿ï¼‰")
        print("âš¡ æœ€é©åŒ–è¶…é«˜ç²¾åº¦å¤‰æ›å®Œäº†ï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='âš¡ æœ€é©åŒ–è¶…é«˜ç²¾åº¦ PDFå¤‰æ›ãƒ„ãƒ¼ãƒ« âš¡')
    parser.add_argument('--input', '-i', required=True, help='å…¥åŠ›PDFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›DXFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--scale', '-s', type=int, default=100, help='ã‚¹ã‚±ãƒ¼ãƒ«')
    parser.add_argument('--visualization', '-v', action='store_true', help='å¯è¦–åŒ–ç”»åƒã‚’ç”Ÿæˆ')
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
    if args.output:
        output_path = f"output/{args.output}"
    else:
        base_name = os.path.splitext(os.path.basename(args.input))[0]
        now = datetime.now()
        timestamp = now.strftime("%Y%m%d_%H%M")
        output_path = f"output/{timestamp}_{base_name}_optimized_ultra.dxf"
    
    # å¤‰æ›å®Ÿè¡Œ
    success = convert_pdf_optimized_ultra(
        args.input,
        output_path,
        args.scale,
        args.visualization
    )
    
    if success:
        print("âœ… æœ€é©åŒ–è¶…é«˜ç²¾åº¦å¤‰æ›ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        sys.exit(0)
    else:
        print("âŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
