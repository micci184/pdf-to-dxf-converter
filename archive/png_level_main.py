#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ª PDF to DXF ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼
ç„¡é§„ãªç·šã‚’é™¤å»ã—ã€PNGç”»åƒã¨åŒç­‰ã®ç¶ºéº—ã•ã‚’å®Ÿç¾
"""

import os
import sys
import argparse
import cv2
import numpy as np
import pdf2image
from datetime import datetime
from sklearn.cluster import DBSCAN
from enhanced_dxf_writer import EnhancedDXFWriter

# EasyOCRã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import easyocr
    EASYOCR_AVAILABLE = True
except ImportError:
    EASYOCR_AVAILABLE = False


class PNGLevelConverter:
    """PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ªå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, pdf_path):
        """åˆæœŸåŒ–"""
        self.pdf_path = pdf_path
        self.images = []
        self.ocr_reader = None
        self.initialize_ocr()
        self.load_pdf()
    
    def initialize_ocr(self):
        """OCRåˆæœŸåŒ–"""
        if not EASYOCR_AVAILABLE:
            return
        
        try:
            print("ğŸ”¤ OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
            self.ocr_reader = easyocr.Reader(['ja', 'en'], gpu=False)
            print("âœ… OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ OCRåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.ocr_reader = None
    
    def load_pdf(self):
        """é«˜å“è³ªPDFãƒ­ãƒ¼ãƒ‰"""
        try:
            print("ğŸ“– é«˜å“è³ªPDFèª­ã¿è¾¼ã¿ä¸­...")
            # 400dpiã§é«˜è§£åƒåº¦å¤‰æ›ï¼ˆç²¾åº¦å‘ä¸Šï¼‰
            images = pdf2image.convert_from_path(self.pdf_path, dpi=400)
            
            for img in images:
                cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                self.images.append(cv_img)
            
            print(f"âœ… é«˜å“è³ªPDFèª­ã¿è¾¼ã¿å®Œäº†: {len(self.images)}ãƒšãƒ¼ã‚¸ (400dpi)")
        except Exception as e:
            raise Exception(f"PDFèª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")
    
    def smart_preprocessing(self, image):
        """PNGç”»è³ªãƒ¬ãƒ™ãƒ«å‰å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # ã‚«ãƒ©ãƒ¼æƒ…å ±ã‚’ä¿æŒ
        original = image.copy()
        
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. é«˜å“è³ªãƒã‚¤ã‚ºé™¤å»ï¼ˆæ”¹è‰¯ï¼‰
        denoised = cv2.fastNlMeansDenoising(gray, None, 8, 7, 21)
        
        # 2. ã‚¬ãƒ³ãƒè£œæ­£ã§ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
        gamma = 0.9
        look_up_table = np.array([((i / 255.0) ** gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
        gamma_corrected = cv2.LUT(denoised, look_up_table)
        
        # 3. CLAHEé©ç”¨
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        clahe_image = clahe.apply(gamma_corrected)
        
        # 4. é©å¿œçš„äºŒå€¤åŒ–ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰
        binary = cv2.adaptiveThreshold(
            clahe_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 7, 2
        )
        
        # 5. è»½å¾®ãªãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†
        kernel = np.ones((1, 1), np.uint8)
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        return original, gray, cleaned
    
    def detect_smart_color_lines(self, original_image):
        """è³¢ã„è‰²ç·šæ¤œå‡ºï¼ˆèµ¤æ–‡å­—å¯¾å¿œç‰ˆï¼‰"""
        # HSVå¤‰æ›
        hsv = cv2.cvtColor(original_image, cv2.COLOR_BGR2HSV)
        
        lines_by_color = {}
        
        # é’ã„ç·šã®æ¤œå‡ºï¼ˆå¤§å¹…æ”¹è‰¯ï¼‰
        # è¤‡æ•°ã®é’è‰²åŸŸã‚’çµ±åˆ
        blue_masks = []
        
        # æ¨™æº–çš„ãªé’
        blue_lower1 = np.array([95, 40, 40])
        blue_upper1 = np.array([135, 255, 255])
        blue_masks.append(cv2.inRange(hsv, blue_lower1, blue_upper1))
        
        # æš—ã„é’
        blue_lower2 = np.array([100, 50, 20])
        blue_upper2 = np.array([125, 200, 150])
        blue_masks.append(cv2.inRange(hsv, blue_lower2, blue_upper2))
        
        # BGRã§ã®é’æ¤œå‡ºï¼ˆé‡è¦ï¼‰
        bgr_blue_lower1 = np.array([80, 30, 30])
        bgr_blue_upper1 = np.array([255, 150, 150])
        blue_masks.append(cv2.inRange(original_image, bgr_blue_lower1, bgr_blue_upper1))
        
        # è–„ã„é’
        bgr_blue_lower2 = np.array([60, 0, 0])
        bgr_blue_upper2 = np.array([255, 80, 80])
        blue_masks.append(cv2.inRange(original_image, bgr_blue_lower2, bgr_blue_upper2))
        
        # å…¨ã¦ã®é’ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        blue_mask = blue_masks[0]
        for mask in blue_masks[1:]:
            blue_mask = cv2.bitwise_or(blue_mask, mask)
        
        # ãƒã‚¤ã‚ºé™¤å»ï¼ˆç©ã‚„ã‹ï¼‰
        kernel = np.ones((2, 2), np.uint8)
        blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel)
        
        blue_lines = cv2.HoughLinesP(
            blue_mask, rho=1, theta=np.pi/180, threshold=20,
            minLineLength=15, maxLineGap=20
        )
        
        if blue_lines is not None:
            # ç·šåˆ†ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_blue = self.filter_meaningful_lines(blue_lines)
            lines_by_color['blue'] = [(x1, y1, x2, y2, 'blue') for x1, y1, x2, y2 in filtered_blue]
        else:
            lines_by_color['blue'] = []
        
        # ç·‘ã®ç·šã®æ¤œå‡ºï¼ˆè›å…‰ç·‘å¯¾å¿œå¼·åŒ–ï¼‰
        green_masks = []
        
        # æ¨™æº–çš„ãªç·‘
        green_lower1 = np.array([40, 50, 50])
        green_upper1 = np.array([80, 255, 255])
        green_masks.append(cv2.inRange(hsv, green_lower1, green_upper1))
        
        # è›å…‰ç·‘ï¼ˆæ˜ã‚‹ã„ç·‘ï¼‰
        green_lower2 = np.array([45, 100, 100])
        green_upper2 = np.array([75, 255, 255])
        green_masks.append(cv2.inRange(hsv, green_lower2, green_upper2))
        
        # BGRã§ã®ç·‘æ¤œå‡º
        bgr_green_lower1 = np.array([30, 80, 30])
        bgr_green_upper1 = np.array([150, 255, 150])
        green_masks.append(cv2.inRange(original_image, bgr_green_lower1, bgr_green_upper1))
        
        # è–„ã„ç·‘
        bgr_green_lower2 = np.array([0, 60, 0])
        bgr_green_upper2 = np.array([80, 255, 80])
        green_masks.append(cv2.inRange(original_image, bgr_green_lower2, bgr_green_upper2))
        
        # å…¨ã¦ã®ç·‘ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        green_mask = green_masks[0]
        for mask in green_masks[1:]:
            green_mask = cv2.bitwise_or(green_mask, mask)
        
        # ãƒã‚¤ã‚ºé™¤å»ï¼ˆç©ã‚„ã‹ï¼‰
        green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)
        
        green_lines = cv2.HoughLinesP(
            green_mask, rho=1, theta=np.pi/180, threshold=20,
            minLineLength=15, maxLineGap=20
        )
        
        if green_lines is not None:
            # ç·šåˆ†ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            filtered_green = self.filter_meaningful_lines(green_lines)
            lines_by_color['green'] = [(x1, y1, x2, y2, 'green') for x1, y1, x2, y2 in filtered_green]
        else:
            lines_by_color['green'] = []
        
        # ğŸ”´ èµ¤ã„ç·šã®æ¤œå‡ºï¼ˆæ‰‹æ›¸ãæ–‡å­—å¯¾å¿œï¼‰
        red_masks = []
        
        # æ¨™æº–çš„ãªèµ¤ï¼ˆHSVï¼‰
        red_lower1 = np.array([0, 50, 50])
        red_upper1 = np.array([10, 255, 255])
        red_masks.append(cv2.inRange(hsv, red_lower1, red_upper1))
        
        # èµ¤ã®ä¸Šä½åŸŸï¼ˆHSVï¼‰
        red_lower2 = np.array([170, 50, 50])
        red_upper2 = np.array([180, 255, 255])
        red_masks.append(cv2.inRange(hsv, red_lower2, red_upper2))
        
        # æš—ã„èµ¤ï¼ˆHSVï¼‰
        red_lower3 = np.array([0, 80, 30])
        red_upper3 = np.array([15, 255, 200])
        red_masks.append(cv2.inRange(hsv, red_lower3, red_upper3))
        
        # BGRã§ã®èµ¤æ¤œå‡ºï¼ˆé‡è¦ï¼‰
        bgr_red_lower1 = np.array([30, 30, 80])
        bgr_red_upper1 = np.array([150, 150, 255])
        red_masks.append(cv2.inRange(original_image, bgr_red_lower1, bgr_red_upper1))
        
        # è–„ã„èµ¤
        bgr_red_lower2 = np.array([0, 0, 60])
        bgr_red_upper2 = np.array([80, 80, 255])
        red_masks.append(cv2.inRange(original_image, bgr_red_lower2, bgr_red_upper2))
        
        # å…¨ã¦ã®èµ¤ãƒã‚¹ã‚¯ã‚’çµ±åˆ
        red_mask = red_masks[0]
        for mask in red_masks[1:]:
            red_mask = cv2.bitwise_or(red_mask, mask)
        
        # ãƒã‚¤ã‚ºé™¤å»ï¼ˆç©ã‚„ã‹ï¼‰
        red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
        
        red_lines = cv2.HoughLinesP(
            red_mask, rho=1, theta=np.pi/180, threshold=20,
            minLineLength=15, maxLineGap=15
        )
        
        if red_lines is not None:
            # ç·šåˆ†ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆèµ¤ã¯æ‰‹æ›¸ããªã®ã§ç·©ã‚ã«ï¼‰
            filtered_red = self.filter_meaningful_lines(red_lines)
            lines_by_color['red'] = [(x1, y1, x2, y2, 'red') for x1, y1, x2, y2 in filtered_red]
        else:
            lines_by_color['red'] = []
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒã‚¹ã‚¯ä¿å­˜ï¼ˆæ”¹è‰¯ï¼‰
        cv2.imwrite('debug_blue_mask_v2.png', blue_mask)
        cv2.imwrite('debug_green_mask_v2.png', green_mask)
        cv2.imwrite('debug_red_mask_v2.png', red_mask)
        print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°v2: é’ãƒ»ç·‘ãƒ»èµ¤ãƒã‚¹ã‚¯ã‚’ä¿å­˜ (é’:{len(lines_by_color['blue'])}æœ¬, ç·‘:{len(lines_by_color['green'])}æœ¬, èµ¤:{len(lines_by_color['red'])}æœ¬)")
        
        return lines_by_color
    
    def filter_meaningful_lines(self, lines):
        """æ„å‘³ã®ã‚ã‚‹ç·šã®ã¿ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        if lines is None or len(lines) == 0:
            return []
        
        lines_reshaped = lines.reshape(-1, 4)
        filtered_lines = []
        
        for line in lines_reshaped:
            x1, y1, x2, y2 = line
            
            # ç·šã®é•·ã•ã‚’è¨ˆç®—
            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            
            # çŸ­ã™ãã‚‹ç·šã¯é™¤å¤–ï¼ˆé–¾å€¤ã‚’ä¸‹ã’ã‚‹ï¼‰
            if length < 10:
                continue
            
            # è§’åº¦ã‚’è¨ˆç®—
            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            
            # æ°´å¹³ç·šãƒ»å‚ç›´ç·šãƒ»45åº¦ç·šã‚’å„ªå…ˆï¼ˆè¨±å®¹ç¯„å›²æ‹¡å¤§ï¼‰
            if (abs(angle) < 10 or abs(angle - 90) < 10 or 
                abs(angle - 180) < 10 or abs(angle + 90) < 10 or
                abs(angle - 45) < 15 or abs(angle + 45) < 15):
                filtered_lines.append(line)
            elif length > 30:  # é•·ã„ç·šã¯è§’åº¦ã«é–¢ä¿‚ãªãæ¡ç”¨ï¼ˆé–¾å€¤ã‚’ä¸‹ã’ã‚‹ï¼‰
                filtered_lines.append(line)
        
        return filtered_lines
    
    def extract_main_structure_lines(self, binary):
        """ä¸»è¦æ§‹é€ ç·šã®ã¿ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        # ã‚ˆã‚Šç·©ã„é–¾å€¤ã§ä¸»è¦ãªç·šã‚’æ¤œå‡º
        lines = cv2.HoughLinesP(
            binary, rho=1, theta=np.pi/180, threshold=50,
            minLineLength=25, maxLineGap=20
        )
        
        if lines is None:
            return []
        
        # ç·šåˆ†ã®çµ±åˆã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_lines = self.filter_meaningful_lines(lines)
        clustered_lines = self.cluster_similar_lines(filtered_lines)
        
        return clustered_lines
    
    def cluster_similar_lines(self, lines):
        """é¡ä¼¼ç·šåˆ†ã‚’çµ±åˆ"""
        if len(lines) == 0:
            return []
        
        # ç·šåˆ†ã®ä¸­ç‚¹ã¨è§’åº¦ã§ç‰¹å¾´é‡ã‚’ä½œæˆ
        features = []
        for x1, y1, x2, y2 in lines:
            mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2
            angle = np.arctan2(y2 - y1, x2 - x1)
            length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
            features.append([mid_x, mid_y, angle, length])
        
        features = np.array(features)
        
        # DBSCAN ã§é¡ä¼¼ç·šåˆ†ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        if len(features) > 10:
            clustering = DBSCAN(eps=20, min_samples=2).fit(features[:, :2])
            labels = clustering.labels_
            
            # å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‹ã‚‰ä»£è¡¨ç·šåˆ†ã‚’é¸æŠ
            clustered_lines = []
            unique_labels = set(labels)
            
            for label in unique_labels:
                if label == -1:  # ãƒã‚¤ã‚º
                    continue
                
                cluster_indices = np.where(labels == label)[0]
                cluster_lines = [lines[i] for i in cluster_indices]
                
                # æœ€é•·ã®ç·šåˆ†ã‚’ä»£è¡¨ã¨ã—ã¦é¸æŠ
                best_line = max(cluster_lines, key=lambda l: np.sqrt((l[2]-l[0])**2 + (l[3]-l[1])**2))
                clustered_lines.append(best_line)
            
            # ãƒã‚¤ã‚ºï¼ˆå˜ç‹¬ç·šåˆ†ï¼‰ã®ä¸­ã§é•·ã„ã‚‚ã®ã‚’è¿½åŠ 
            noise_indices = np.where(labels == -1)[0]
            for idx in noise_indices:
                line = lines[idx]
                length = np.sqrt((line[2]-line[0])**2 + (line[3]-line[1])**2)
                if length > 60:  # é•·ã„å˜ç‹¬ç·šåˆ†ã¯æ¡ç”¨
                    clustered_lines.append(line)
            
            return clustered_lines
        else:
            return lines
    
    def smart_text_recognition(self, image):
        """è³¢ã„ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ï¼ˆèµ¤æ–‡å­—å¯¾å¿œç‰ˆï¼‰"""
        if not self.ocr_reader:
            return []
        
        try:
            print("ğŸ”¤ è³¢ã„ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å‡¦ç†ä¸­ï¼ˆèµ¤æ–‡å­—å¯¾å¿œï¼‰...")
            
            # å…¨ä½“ç”»åƒã§ã®OCR
            results = self.ocr_reader.readtext(image)
            
            # èµ¤ã„æ–‡å­—é ˜åŸŸã‚’ç‰¹åˆ¥ã«å¼·èª¿ã—ã¦OCR
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # èµ¤ã„ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã®æŠ½å‡º
            red_lower1 = np.array([0, 50, 50])
            red_upper1 = np.array([10, 255, 255])
            red_mask1 = cv2.inRange(hsv, red_lower1, red_upper1)
            
            red_lower2 = np.array([170, 50, 50])
            red_upper2 = np.array([180, 255, 255])
            red_mask2 = cv2.inRange(hsv, red_lower2, red_upper2)
            
            red_mask = cv2.bitwise_or(red_mask1, red_mask2)
            
            # èµ¤ã„é ˜åŸŸã‚’ç™½ãã€ä»–ã‚’é»’ãã—ã¦èµ¤æ–‡å­—ã‚’å¼·èª¿
            red_enhanced = cv2.bitwise_and(image, image, mask=red_mask)
            red_gray = cv2.cvtColor(red_enhanced, cv2.COLOR_BGR2GRAY)
            
            # èµ¤ã„æ–‡å­—ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€å°‚ç”¨OCRå®Ÿè¡Œ
            if cv2.countNonZero(red_mask) > 100:  # èµ¤ã„é ˜åŸŸãŒã‚ã‚‹ç¨‹åº¦å­˜åœ¨ã™ã‚‹å ´åˆ
                print("ğŸ”´ èµ¤ã„ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æ¤œå‡ºã€å°‚ç”¨OCRå®Ÿè¡Œä¸­...")
                red_results = self.ocr_reader.readtext(red_gray)
                results.extend(red_results)
            
            text_regions = []
            seen_texts = set()  # é‡è¤‡é™¤å»ç”¨
            
            for (bbox, text, confidence) in results:
                if confidence > 0.4:  # èµ¤æ–‡å­—ã¯æ‰‹æ›¸ããªã®ã§ä¿¡é ¼åº¦ã‚’ä¸‹ã’ã‚‹
                    # æ„å‘³ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ã¿
                    cleaned_text = text.strip()
                    if len(cleaned_text) > 0 and not cleaned_text.isspace() and cleaned_text not in seen_texts:
                        seen_texts.add(cleaned_text)
                        
                        x_coords = [point[0] for point in bbox]
                        y_coords = [point[1] for point in bbox]
                        x1, y1 = int(min(x_coords)), int(min(y_coords))
                        x2, y2 = int(max(x_coords)), int(max(y_coords))
                        
                        # èµ¤ã„ãƒ†ã‚­ã‚¹ãƒˆã‹ã©ã†ã‹åˆ¤å®š
                        text_center_x, text_center_y = (x1 + x2) // 2, (y1 + y2) // 2
                        is_red_text = False
                        if 0 <= text_center_y < red_mask.shape[0] and 0 <= text_center_x < red_mask.shape[1]:
                            is_red_text = red_mask[text_center_y, text_center_x] > 0
                        
                        text_regions.append({
                            'bbox': (x1, y1, x2, y2),
                            'text': cleaned_text,
                            'confidence': confidence,
                            'color': 'red' if is_red_text else 'black'
                        })
            
            # ãƒ‡ãƒãƒƒã‚°ç”¨: èµ¤ãƒã‚¹ã‚¯ã‚’ä¿å­˜
            cv2.imwrite('debug_red_text_mask.png', red_mask)
            
            red_text_count = sum(1 for t in text_regions if t.get('color') == 'red')
            print(f"âœ… è³¢ã„ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å®Œäº†: {len(text_regions)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆ (èµ¤æ–‡å­—: {red_text_count}å€‹)")
            return text_regions
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def process_pdf_png_level(self):
        """PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ªã§å‡¦ç†"""
        try:
            print("ğŸ¨ PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ªå‡¦ç†é–‹å§‹")
            
            all_elements = {
                'blue_lines': [],
                'green_lines': [],
                'red_lines': [],
                'main_lines': [],
                'text_regions': []
            }
            
            for i, image in enumerate(self.images):
                print(f"ğŸ” ãƒšãƒ¼ã‚¸ {i+1} ã‚’PNGå“è³ªå‡¦ç†ä¸­...")
                
                # 1. PNGå“è³ªå‰å‡¦ç†
                original, gray, binary = self.smart_preprocessing(image)
                
                # 2. è³¢ã„è‰²ç·šæ¤œå‡º
                color_lines = self.detect_smart_color_lines(original)
                all_elements['blue_lines'].extend(color_lines.get('blue', []))
                all_elements['green_lines'].extend(color_lines.get('green', []))
                all_elements['red_lines'].extend(color_lines.get('red', []))
                
                # 3. ä¸»è¦æ§‹é€ ç·šæŠ½å‡º
                main_lines = self.extract_main_structure_lines(binary)
                all_elements['main_lines'].extend(main_lines)
                
                # 4. è³¢ã„ãƒ†ã‚­ã‚¹ãƒˆèªè­˜
                text_regions = self.smart_text_recognition(original)
                all_elements['text_regions'].extend(text_regions)
                
                print(f"âœ… ãƒšãƒ¼ã‚¸ {i+1} PNGå“è³ªå‡¦ç†å®Œäº†:")
                print(f"   ğŸ”µ é’ã„ç·š: {len(color_lines.get('blue', []))}æœ¬")
                print(f"   ğŸŸ¢ ç·‘ã®ç·š: {len(color_lines.get('green', []))}æœ¬")
                print(f"   ğŸ”´ èµ¤ã„ç·š: {len(color_lines.get('red', []))}æœ¬")
                print(f"   ğŸ“ ä¸»è¦ç·š: {len(main_lines)}æœ¬")
                print(f"   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {len(text_regions)}å€‹")
            
            return all_elements
            
        except Exception as e:
            print(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None


def convert_pdf_png_level(input_path, output_path, scale=100):
    """PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ªPDFå¤‰æ›"""
    try:
        print("=" * 60)
        print("ğŸ¨ PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ª PDFå¤‰æ›ãƒ„ãƒ¼ãƒ« ğŸ¨")
        print("=" * 60)
        
        # 1. å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        converter = PNGLevelConverter(input_path)
        
        # 2. PNGå“è³ªå‡¦ç†
        elements = converter.process_pdf_png_level()
        
        if elements is None:
            return False
        
        # 3. DXFç”Ÿæˆ
        print("ğŸ“ PNGå“è³ªDXFç”Ÿæˆä¸­...")
        dxf_writer = EnhancedDXFWriter()
        
        if scale != 1:
            dxf_writer.set_scale(1.0 / scale)
        
        # PNGå“è³ªè¦ç´ ã‚’DXFã«è¿½åŠ 
        dxf_elements = {
            'lines': elements['main_lines'],
            'blue_lines': elements['blue_lines'],
            'green_lines': elements['green_lines'],
            'red_lines': elements['red_lines'],
            'text_regions': elements['text_regions']
        }
        
        dxf_writer.add_elements(dxf_elements)
        dxf_writer.save(output_path)
        
        # 4. çµæœè¡¨ç¤º
        total_lines = len(elements['main_lines']) + len(elements['blue_lines']) + len(elements['green_lines']) + len(elements['red_lines'])
        
        print("=" * 60)
        print("ğŸ‰ PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ªå¤‰æ›å®Œäº† ğŸ‰")
        print("=" * 60)
        print(f"ğŸ“ å…¥åŠ›: {input_path}")
        print(f"ğŸ“ å‡ºåŠ›: {output_path}")
        print(f"ğŸ“Š PNGå“è³ªæ¤œå‡ºçµæœ:")
        print(f"   ğŸ”µ é’ã„ç·š: {len(elements['blue_lines'])}æœ¬")
        print(f"   ğŸŸ¢ ç·‘ã®ç·š: {len(elements['green_lines'])}æœ¬")
        print(f"   ğŸ”´ èµ¤ã„ç·š: {len(elements['red_lines'])}æœ¬")
        print(f"   ğŸ“ ä¸»è¦ç·š: {len(elements['main_lines'])}æœ¬")
        print(f"   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {len(elements['text_regions'])}å€‹")
        print(f"   ğŸ¯ ç·ç·šåˆ†æ•°: {total_lines}æœ¬ (æœ€é©åŒ–æ¸ˆã¿)")
        print("ğŸ¨ PNGç”»åƒãƒ¬ãƒ™ãƒ«ã®ç¶ºéº—ã•ã§å¤‰æ›å®Œäº†ï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ğŸ¨ PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ª PDFå¤‰æ›ãƒ„ãƒ¼ãƒ« ğŸ¨')
    parser.add_argument('--input', '-i', required=True, help='å…¥åŠ›PDFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›DXFãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--scale', '-s', type=int, default=100, help='ã‚¹ã‚±ãƒ¼ãƒ«')
    
    args = parser.parse_args()
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
    if args.output:
        output_path = f"output/{args.output}"
    else:
        base_name = os.path.splitext(os.path.basename(args.input))[0]
        now = datetime.now()
        timestamp = now.strftime("%Y%m%d_%H%M")
        output_path = f"output/{timestamp}_{base_name}_png_level.dxf"
    
    # å¤‰æ›å®Ÿè¡Œ
    success = convert_pdf_png_level(
        args.input,
        output_path,
        args.scale
    )
    
    if success:
        print("âœ… PNGç”»åƒãƒ¬ãƒ™ãƒ«å“è³ªå¤‰æ›ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        sys.exit(0)
    else:
        print("âŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
