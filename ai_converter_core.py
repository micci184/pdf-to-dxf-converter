#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ« AIå¤‰æ›ãƒ„ãƒ¼ãƒ« - ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æœ€æ–°ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’é§†ä½¿ã—ãŸæ‰‹æ›¸ãå›³é¢å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import cv2
import numpy as np
import pdf2image
from datetime import datetime
import easyocr
from sklearn.cluster import DBSCAN
from scipy import ndimage
from skimage import morphology, measure
import tensorflow as tf


class WorldClassAIConverter:
    """ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«AIå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.ocr_reader = None
        self.initialize_ai_models()
    
    def initialize_ai_models(self):
        """AI ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        try:
            # EasyOCR ã®åˆæœŸåŒ–ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œï¼‰
            self.ocr_reader = easyocr.Reader(['ja', 'en'], gpu=False)
            print("âœ… OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ OCRãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def load_pdf_ultra_high_quality(self, pdf_path):
        """è¶…é«˜å“è³ªPDFãƒ­ãƒ¼ãƒ‰"""
        try:
            # 600dpiã§è¶…é«˜è§£åƒåº¦å¤‰æ›
            images = pdf2image.convert_from_path(pdf_path, dpi=600)
            cv_images = []
            
            for img in images:
                cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                cv_images.append(cv_img)
            
            print(f"âœ… è¶…é«˜å“è³ªPDFèª­ã¿è¾¼ã¿å®Œäº†: {len(cv_images)}ãƒšãƒ¼ã‚¸ (600dpi)")
            return cv_images
        except Exception as e:
            raise Exception(f"PDFèª­ã¿è¾¼ã¿å¤±æ•—: {str(e)}")
    
    def ai_enhanced_preprocessing(self, image):
        """AIå¼·åŒ–å‰å‡¦ç†"""
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. ãƒã‚¤ã‚ºé™¤å»ï¼ˆNon-local Means Denoisingï¼‰
        denoised = cv2.fastNlMeansDenoising(gray, h=10)
        
        # 2. ã‚·ãƒ£ãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(denoised, -1, kernel)
        
        # 3. CLAHEï¼ˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ï¼‰
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(sharpened)
        
        # 4. é©å¿œçš„äºŒå€¤åŒ–
        binary = cv2.adaptiveThreshold(
            enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 9, 2
        )
        
        return enhanced, binary
    
    def ai_text_recognition(self, image):
        """AIæ–‡å­—èªè­˜"""
        if self.ocr_reader is None:
            return []
        
        try:
            # EasyOCRã§é«˜ç²¾åº¦æ–‡å­—èªè­˜
            results = self.ocr_reader.readtext(image)
            
            text_regions = []
            for (bbox, text, confidence) in results:
                if confidence > 0.3:  # ä¿¡é ¼åº¦30%ä»¥ä¸Š
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—
                    x_coords = [point[0] for point in bbox]
                    y_coords = [point[1] for point in bbox]
                    x1, y1 = int(min(x_coords)), int(min(y_coords))
                    x2, y2 = int(max(x_coords)), int(max(y_coords))
                    
                    text_regions.append({
                        'bbox': (x1, y1, x2, y2),
                        'text': text,
                        'confidence': confidence
                    })
            
            print(f"âœ… æ–‡å­—èªè­˜å®Œäº†: {len(text_regions)}å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆ")
            return text_regions
        except Exception as e:
            print(f"âš ï¸ æ–‡å­—èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def ai_line_detection(self, binary_image, text_regions):
        """AIç·šåˆ†æ¤œå‡º"""
        # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’ãƒã‚¹ã‚¯
        text_mask = np.zeros(binary_image.shape, dtype=np.uint8)
        for region in text_regions:
            x1, y1, x2, y2 = region['bbox']
            cv2.rectangle(text_mask, (x1-5, y1-5), (x2+5, y2+5), 255, -1)
        
        # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’é™¤å¤–
        masked_binary = cv2.bitwise_and(binary_image, cv2.bitwise_not(text_mask))
        
        # ç·šåˆ†æ¤œå‡º
        lines = []
        
        # æ°´å¹³ç·šæ¤œå‡º
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))
        horizontal_lines = cv2.morphologyEx(masked_binary, cv2.MORPH_OPEN, horizontal_kernel)
        h_lines = cv2.HoughLinesP(horizontal_lines, 1, np.pi/180, 60, minLineLength=40, maxLineGap=10)
        
        if h_lines is not None:
            for line in h_lines:
                x1, y1, x2, y2 = line[0]
                lines.append((x1, y1, x2, y2, 'horizontal'))
        
        # å‚ç›´ç·šæ¤œå‡º
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 30))
        vertical_lines = cv2.morphologyEx(masked_binary, cv2.MORPH_OPEN, vertical_kernel)
        v_lines = cv2.HoughLinesP(vertical_lines, 1, np.pi/180, 60, minLineLength=40, maxLineGap=10)
        
        if v_lines is not None:
            for line in v_lines:
                x1, y1, x2, y2 = line[0]
                lines.append((x1, y1, x2, y2, 'vertical'))
        
        # ãã®ä»–ã®ç·šåˆ†
        other_lines = cv2.HoughLinesP(masked_binary, 1, np.pi/180, 50, minLineLength=30, maxLineGap=15)
        if other_lines is not None:
            for line in other_lines:
                x1, y1, x2, y2 = line[0]
                angle = np.degrees(np.arctan2(y2 - y1, x2 - x1)) % 180
                if not (abs(angle) < 15 or abs(angle - 90) < 15):
                    lines.append((x1, y1, x2, y2, 'other'))
        
        return lines
    
    def ai_shape_recognition(self, binary_image):
        """AIå›³å½¢èªè­˜"""
        shapes = []
        
        # è¼ªéƒ­æ¤œå‡º
        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 100:  # å°ã•ã™ãã‚‹è¼ªéƒ­ã¯ç„¡è¦–
                continue
            
            # è¼ªéƒ­ã®è¿‘ä¼¼
            epsilon = 0.02 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # å›³å½¢ã®åˆ†é¡
            if len(approx) == 3:
                shapes.append({'type': 'triangle', 'contour': approx})
            elif len(approx) == 4:
                # é•·æ–¹å½¢ã‹ã©ã†ã‹åˆ¤å®š
                x, y, w, h = cv2.boundingRect(approx)
                aspect_ratio = float(w) / h
                shapes.append({'type': 'rectangle', 'contour': approx, 'bbox': (x, y, w, h)})
            elif len(approx) > 8:
                # å††å½¢ã®å¯èƒ½æ€§
                (x, y), radius = cv2.minEnclosingCircle(contour)
                if radius > 10:
                    shapes.append({'type': 'circle', 'center': (int(x), int(y)), 'radius': int(radius)})
        
        return shapes


def create_output_filename(base_name):
    """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆæ—¥ä»˜æ™‚é–“ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãï¼‰"""
    now = datetime.now()
    timestamp = now.strftime("%Y%m%d_%H%M")
    return f"output/{timestamp}_{base_name}"


if __name__ == "__main__":
    print("ğŸš€ ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ« AIå¤‰æ›ãƒ„ãƒ¼ãƒ« - ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«")
    print("æœ€æ–°ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’é§†ä½¿ã—ãŸæ‰‹æ›¸ãå›³é¢å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ")
